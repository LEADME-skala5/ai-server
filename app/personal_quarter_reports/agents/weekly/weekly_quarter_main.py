#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì£¼ê°„ ë³´ê³ ì„œ ë¶„ê¸°ë³„ ë°°ì¹˜ í‰ê°€ ì‹œìŠ¤í…œ - í™˜ê²½ë³€ìˆ˜ ë²„ì „
ì‹¤í–‰: python main.py
"""

import pandas as pd
import json
import openai
from typing import Dict, List, Any, Optional, Tuple
import os
from datetime import datetime
from pathlib import Path
import logging
import pymysql
from pinecone import Pinecone, ServerlessSpec
import random
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# =====================================
# ì„¤ì • í´ë˜ìŠ¤
class Config:
    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
        self.OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
        self.PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')
        
        # ëª¨ë¸ ë° ê¸°ë³¸ ì„¤ì •
        self.MODEL = os.getenv('OPENAI_MODEL', 'gpt-4-turbo')
        self.OUTPUT_PATH = os.getenv('OUTPUT_PATH', './output')
        
        # Pinecone ì„¤ì •
        self.PINECONE_INDEX_NAME = os.getenv('PINECONE_INDEX_NAME', 'skore')
        
        # MariaDB ì„¤ì • - í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
        self.DB_CONFIG = {
            'host': os.getenv('DB_HOST'),
            'port': int(os.getenv('DB_PORT', 3306)),
            'user': os.getenv('DB_USER'),
            'password': os.getenv('DB_PASSWORD'),
            'database': os.getenv('DB_NAME'),
            'charset': os.getenv('DB_CHARSET', 'utf8mb4')
        }
        
        # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ê²€ì¦
        self._validate_config()
    
    def _validate_config(self):
        """í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ê²€ì¦"""
        required_vars = {
            'OPENAI_API_KEY': self.OPENAI_API_KEY,
            'PINECONE_API_KEY': self.PINECONE_API_KEY,
            'DB_HOST': self.DB_CONFIG['host'],
            'DB_USER': self.DB_CONFIG['user'],
            'DB_PASSWORD': self.DB_CONFIG['password'],
            'DB_NAME': self.DB_CONFIG['database']
        }
        
        missing_vars = [var for var, value in required_vars.items() if not value]
        
        if missing_vars:
            raise ValueError(
                f"í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_vars)}\n"
                f".env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”."
            )
        
        logger.info("âœ… ëª¨ë“  í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

# =====================================
# ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì
class DatabaseManager:
    def __init__(self, db_config):
        self.db_config = db_config
    
    def connect(self):
        """MariaDB ì—°ê²°"""
        try:
            connection = pymysql.connect(**self.db_config)
            logger.info("MariaDB ì—°ê²° ì„±ê³µ")
            return connection
        except Exception as e:
            logger.error(f"MariaDB ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            raise
    
    def load_team_data(self):
        """íŒ€ ê¸°ì¤€ ë° ëª©í‘œ ë°ì´í„° ë¡œë“œ"""
        logger.info("MariaDBì—ì„œ íŒ€ ë°ì´í„° ë¡œë“œ ì‹œì‘")
        
        connection = self.connect()
        try:
            # team_criteria í…Œì´ë¸” ë¡œë“œ
            criteria_query = "SELECT * FROM team_criteria"
            team_criteria = pd.read_sql(criteria_query, connection)
            logger.info(f"team_criteria ë¡œë“œ ì™„ë£Œ: {len(team_criteria)}ê±´")
            
            # team_goal í…Œì´ë¸” ë¡œë“œ
            goals_query = "SELECT * FROM team_goal"
            team_goals = pd.read_sql(goals_query, connection)
            logger.info(f"team_goal ë¡œë“œ ì™„ë£Œ: {len(team_goals)}ê±´")
            
            return team_criteria, team_goals
            
        finally:
            connection.close()
    
    def get_organization_name(self, organization_id):
        """organization_idë¡œ ì¡°ì§ëª… ì¡°íšŒ - ì‹¤ì œ ì»¬ëŸ¼ëª… ì‚¬ìš©"""
        if not organization_id:
            return "ë¯¸ì§€ì • íŒ€"
            
        logger.info(f"ì¡°ì§ ID {organization_id}ì˜ ì´ë¦„ ì¡°íšŒ ì‹œì‘")
        
        connection = self.connect()
        try:
            # ë¨¼ì € organizations í…Œì´ë¸” êµ¬ì¡° í™•ì¸
            cursor = connection.cursor()
            cursor.execute("DESCRIBE organizations")
            columns = [row[0] for row in cursor.fetchall()]
            logger.info(f"organizations í…Œì´ë¸” ì»¬ëŸ¼: {columns}")
            
            # ê°€ëŠ¥í•œ ID ì»¬ëŸ¼ëª…ë“¤ ì‹œë„
            possible_id_columns = ['id', 'organization_id', 'org_id', 'pk']
            id_column = None
            
            for col in possible_id_columns:
                if col in columns:
                    id_column = col
                    break
            
            if not id_column:
                logger.error(f"organizations í…Œì´ë¸”ì—ì„œ ID ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {columns}")
                return f"ì¡°ì§_{organization_id}"
            
            # ê°€ëŠ¥í•œ ì´ë¦„ ì»¬ëŸ¼ëª…ë“¤ ì‹œë„
            possible_name_columns = ['name', 'org_name', 'organization_name', 'dept_name', 'team_name']
            name_column = None
            
            for col in possible_name_columns:
                if col in columns:
                    name_column = col
                    break
            
            if not name_column:
                logger.error(f"organizations í…Œì´ë¸”ì—ì„œ ì´ë¦„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {columns}")
                return f"ì¡°ì§_{organization_id}"
            
            # ì‹¤ì œ ì¡°ì§ëª… ì¡°íšŒ
            query = f"SELECT {name_column} FROM organizations WHERE {id_column} = %s"
            result = pd.read_sql(query, connection, params=[str(organization_id)])
            
            if not result.empty and not result[name_column].isna().iloc[0]:
                org_name = result[name_column].iloc[0]
                logger.info(f"ì¡°ì§ ID {organization_id}ì˜ ì´ë¦„: {org_name}")
                return str(org_name).strip()
            else:
                logger.warning(f"ì¡°ì§ ID {organization_id}ì— í•´ë‹¹í•˜ëŠ” ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return f"ì¡°ì§_{organization_id}"
                
        except Exception as e:
            logger.error(f"ì¡°ì§ëª… ì¡°íšŒ ì‹¤íŒ¨ (ID: {organization_id}): {e}")
            return f"ì¡°ì§_{organization_id}"
        finally:
            connection.close()

# =====================================
# Pinecone ê´€ë¦¬ì
class PineconeManager:
    def __init__(self, api_key, index_name):
        self.pc = Pinecone(api_key=api_key)
        self.index_name = index_name
        self.index = self.pc.Index(index_name)
        self.namespace = self._detect_namespace()
        
        logger.info(f"Pinecone ì´ˆê¸°í™” ì™„ë£Œ - ì¸ë±ìŠ¤: {index_name}")
        logger.info(f"ì‚¬ìš© ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {self.namespace}")
    
    def _detect_namespace(self):
        """ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìë™ ê°ì§€"""
        try:
            stats = self.index.describe_index_stats()
            if hasattr(stats, 'namespaces') and stats.namespaces:
                namespaces = list(stats.namespaces.keys())
                if namespaces:
                    for ns in namespaces:
                        if stats.namespaces[ns].vector_count > 0:
                            logger.info(f"ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê°ì§€: '{ns}' (ë²¡í„° ìˆ˜: {stats.namespaces[ns].vector_count})")
                            return ns
                    return namespaces[0]
            return ""
        except Exception as e:
            logger.warning(f"ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê°ì§€ ì‹¤íŒ¨: {e}")
            return ""
    
    def search_user_data(self, user_id, top_k=100):
        """íŠ¹ì • ì‚¬ìš©ì ë°ì´í„° ê²€ìƒ‰"""
        logger.info(f"ì‚¬ìš©ì {user_id} ë°ì´í„° ê²€ìƒ‰ ì‹œì‘")
        
        dummy_vector = [0.0] * 1024
        
        query_params = {
            "vector": dummy_vector,
            "filter": {"user_id": str(user_id)},
            "top_k": top_k,
            "include_metadata": True
        }
        
        if self.namespace:
            query_params["namespace"] = self.namespace
        
        search_results = self.index.query(**query_params)
        logger.info(f"ê²€ìƒ‰ ê²°ê³¼: {len(search_results.matches)}ê±´")
        
        return search_results
    
    def get_available_user_ids(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  user_id ì¡°íšŒ"""
        logger.info("ì‚¬ìš© ê°€ëŠ¥í•œ user_id ì¡°íšŒ ì‹œì‘")
        
        user_ids = set()
        dummy_vector = [0.0] * 1024
        
        # ì—¬ëŸ¬ ë²ˆ ì‹œë„í•˜ì—¬ ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘
        for attempt in range(3):
            try:
                if attempt > 0:
                    dummy_vector = [random.uniform(-1, 1) for _ in range(1024)]
                
                query_params = {
                    "vector": dummy_vector,
                    "top_k": 1000,
                    "include_metadata": True
                }
                
                if self.namespace:
                    query_params["namespace"] = self.namespace
                
                query_result = self.index.query(**query_params)
                
                for match in query_result.matches:
                    if hasattr(match, 'metadata') and match.metadata:
                        for key in ['user_id', 'userId', 'USER_ID', 'employee_id', 'emp_id']:
                            if key in match.metadata:
                                user_ids.add(str(match.metadata[key]))
                
                if user_ids:
                    break
                    
            except Exception as e:
                logger.warning(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
                continue
        
        available_ids = sorted(list(user_ids))
        logger.info(f"ë°œê²¬ëœ user_id: {available_ids}")
        return available_ids

# =====================================
# ë°ì´í„° ì²˜ë¦¬ê¸°
class DataProcessor:
    @staticmethod
    def convert_pinecone_to_dataframe(search_results):
        """Pinecone ê²€ìƒ‰ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        weekly_records = []
        
        for match in search_results.matches:
            metadata = match.metadata
            
            record = {
                'employee_number': metadata.get('user_id'),
                'name': f"User_{metadata.get('user_id')}",
                'done_task': metadata.get('done_task', ''),
                'start_date': metadata.get('start_date'),
                'end_date': metadata.get('end_date'),
                'evaluation_year': metadata.get('evaluation_year'),
                'evaluation_quarter': metadata.get('evaluation_quarter'),
                'organization_id': metadata.get('organization_id'),
                'source_file': metadata.get('source_file', ''),
                'row_index': metadata.get('row_index', '')
            }
            weekly_records.append(record)
        
        df = pd.DataFrame(weekly_records)
        
        # ì¤‘ë³µ ì œê±°
        if not df.empty:
            df = df.drop_duplicates(
                subset=['employee_number', 'start_date', 'end_date'], 
                keep='first'
            )
        
        return df
    
    @staticmethod
    def split_data_by_quarters(employee_data):
        """ì§ì› ë°ì´í„°ë¥¼ ë¶„ê¸°ë³„ë¡œ ë¶„í• """
        if employee_data.empty:
            return {}
        
        # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
        employee_data['start_date_dt'] = pd.to_datetime(employee_data['start_date'], errors='coerce')
        employee_data['end_date_dt'] = pd.to_datetime(employee_data['end_date'], errors='coerce')
        
        # ìœ íš¨í•œ ë‚ ì§œê°€ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
        valid_data = employee_data.dropna(subset=['start_date_dt'])
        
        if valid_data.empty:
            logger.warning("ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        # ë¶„ê¸°ë³„ ë°ì´í„° ë¶„í• 
        quarters = {}
        
        for _, row in valid_data.iterrows():
            start_date = row['start_date_dt']
            year = start_date.year
            month = start_date.month
            
            # ë¶„ê¸° ê³„ì‚° (1-3ì›”: Q1, 4-6ì›”: Q2, 7-9ì›”: Q3, 10-12ì›”: Q4)
            if 1 <= month <= 3:
                quarter = 1
                quarter_start = f"{year}-01-01"
                quarter_end = f"{year}-03-31"
            elif 4 <= month <= 6:
                quarter = 2
                quarter_start = f"{year}-04-01"
                quarter_end = f"{year}-06-30"
            elif 7 <= month <= 9:
                quarter = 3
                quarter_start = f"{year}-07-01"
                quarter_end = f"{year}-09-30"
            else:  # 10-12ì›”
                quarter = 4
                quarter_start = f"{year}-10-01"
                quarter_end = f"{year}-12-31"
            
            quarter_key = f"{year}_Q{quarter}"
            
            if quarter_key not in quarters:
                quarters[quarter_key] = {
                    'data': [],
                    'year': year,
                    'quarter': quarter,
                    'start_date': quarter_start,
                    'end_date': quarter_end
                }
            
            quarters[quarter_key]['data'].append(row.to_dict())
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        for quarter_key in quarters:
            quarters[quarter_key]['dataframe'] = pd.DataFrame(quarters[quarter_key]['data'])
        
        logger.info(f"ë°ì´í„°ë¥¼ {len(quarters)}ê°œ ë¶„ê¸°ë¡œ ë¶„í• : {list(quarters.keys())}")
        return quarters
    
    @staticmethod
    def extract_employee_info_for_quarter(quarter_data, year, quarter):
        """ë¶„ê¸°ë³„ ì§ì› ì •ë³´ ì¶”ì¶œ"""
        if quarter_data.empty:
            return None
            
        info = {
            "name": quarter_data['name'].iloc[0] if 'name' in quarter_data.columns else f"User_{quarter_data['employee_number'].iloc[0]}",
            "employee_number": quarter_data['employee_number'].iloc[0],
            "organization_id": quarter_data['organization_id'].iloc[0] if 'organization_id' in quarter_data.columns else "",
            "evaluation_year": year,
            "evaluation_quarter": quarter,
            "total_weeks": len(quarter_data),
            "total_activities": len(quarter_data)
        }
        
        # ë¶„ê¸°ë³„ ë‚ ì§œ ë²”ìœ„ ì„¤ì •
        if 'start_date' in quarter_data.columns and 'end_date' in quarter_data.columns:
            start_dates = pd.to_datetime(quarter_data['start_date'], errors='coerce').dropna()
            end_dates = pd.to_datetime(quarter_data['end_date'], errors='coerce').dropna()
            if not start_dates.empty and not end_dates.empty:
                info["period"] = f"{start_dates.min().strftime('%Y-%m-%d')} ~ {end_dates.max().strftime('%Y-%m-%d')}"
        
        # ì£¼ê°„ ì—…ë¬´ ë°ì´í„° ì¶”ê°€
        info['weekly_tasks'] = quarter_data[['start_date', 'end_date', 'done_task']].to_dict('records')
        
        return info
    
    @staticmethod
    def filter_team_data_by_org(team_data, org_id, org_keywords):
        """ì¡°ì§ IDë¡œ íŒ€ ë°ì´í„° í•„í„°ë§"""
        if team_data is None or team_data.empty or not org_id:
            return team_data.to_dict('records') if team_data is not None else []
        
        # organization_id ì»¬ëŸ¼ ì°¾ê¸°
        org_column = None
        for col in team_data.columns:
            col_lower = str(col).lower().strip()
            if any(keyword.lower() in col_lower for keyword in org_keywords):
                org_column = col
                break
        
        if org_column:
            filtered_data = team_data[
                team_data[org_column].astype(str) == str(org_id)
            ].to_dict('records')
            logger.info(f"íŒ€ ë°ì´í„° í•„í„°ë§ ì™„ë£Œ: {len(filtered_data)}ê°œ")
            return filtered_data
        
        logger.warning("ì¡°ì§ ID ë§¤ì¹­ ì‹¤íŒ¨, ì „ì²´ ë°ì´í„° ë°˜í™˜")
        return team_data.to_dict('records')

# =====================================
# LLM í‰ê°€ê¸°
class LLMEvaluator:
    def __init__(self, api_key, model="gpt-4-turbo"):
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model
    
    def generate_prompt(self, employee_data, team_goals, team_criteria):
        """í‰ê°€ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        team_categories = self._extract_goal_categories(team_goals)
        
        prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ HR í‰ê°€ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì§ì›ì˜ ì£¼ê°„ ë³´ê³ ì„œë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ê°ê´€ì ì¸ ì„±ê³¼ í‰ê°€ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.

## í‰ê°€ ëŒ€ìƒ ì •ë³´
- ì´ë¦„: {employee_data['name']}
- ì§ì›ë²ˆí˜¸: {employee_data['employee_number']}
- ì¡°ì§ ID: {employee_data['organization_id']}
- í‰ê°€ ê¸°ê°„: {employee_data.get('period', 'N/A')}
- ì´ í‰ê°€ ì£¼ì°¨: {employee_data['total_weeks']}ì£¼

## ì£¼ê°„ë³„ ìˆ˜í–‰ ì—…ë¬´
"""
        
        # ì£¼ê°„ë³„ ì—…ë¬´ ì¶”ê°€
        weekly_tasks = employee_data.get('weekly_tasks', [])
        for i, task in enumerate(weekly_tasks, 1):
            start_date = task.get('start_date', 'N/A')
            end_date = task.get('end_date', 'N/A')
            done_task = task.get('done_task', 'N/A')
            prompt += f"\n**{i}ì£¼ì°¨ ({start_date} ~ {end_date})**\n{done_task}\n"
        
        prompt += f"""

## í‰ê°€ ê²°ê³¼ í˜•ì‹
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¢…í•© í‰ê°€ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

```json
{{
  "teamGoals": [
    {{
      "goalName": "ëª©í‘œëª…",
      "assigned": "ë°°ì •|ë¯¸ë°°ì •",
      "contributionCount": ê¸°ì—¬í™œë™ìˆ˜,
      "contents": [
        {{
          "description": "êµ¬ì²´ì ì¸ ì—…ë¬´ í™œë™ ì„¤ëª…",
          "reference": [
            {{
              "label": "Nì›” Nì£¼ì°¨ weekly ë³´ê³ ì„œ",
               "excerpt": "í•´ë‹¹ ì£¼ì°¨ ë³´ê³ ì„œì—ì„œ ê´€ë ¨ ì—…ë¬´ ë‚´ìš© ë°œì·Œ"
            }}
          ]
        }}
      ]
    }}
  ]
}}
```

## íŒ€ ëª©í‘œ
"""
        for i, category in enumerate(team_categories, 1):
            prompt += f"{i}. {category}\n"
        
        prompt += "\nJSON í˜•ì‹ì„ ì •í™•íˆ ì¤€ìˆ˜í•˜ì—¬ ì‘ë‹µí•´ì£¼ì„¸ìš”."
        
        return prompt
    
    def _extract_goal_categories(self, team_goals):
        """íŒ€ ëª©í‘œì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ - RDB ë°ì´í„° ê¸°ë°˜"""
        if not team_goals:
            logger.warning("íŒ€ ëª©í‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ëª©í‘œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return []
        
        logger.info(f"íŒ€ ëª©í‘œ ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì‹œì‘ - ì´ {len(team_goals)}ê°œ ë ˆì½”ë“œ")
        
        # ì²« ë²ˆì§¸ ë ˆì½”ë“œë¡œ ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸
        if team_goals:
            first_record = team_goals[0]
            logger.info(f"íŒ€ ëª©í‘œ ë°ì´í„° ì»¬ëŸ¼: {list(first_record.keys())}")
        
        # ëª©í‘œëª…/ê³¼ì œëª…ì„ ì°¾ê¸° ìœ„í•œ í‚¤ì›Œë“œ (ìš°ì„ ìˆœìœ„ ìˆœ)
        goal_keywords = [
            'goal_name',        # ëª©í‘œëª…
            'task_name',        # ê³¼ì œëª…  
            'objective_name',   # ëª©ì ëª…
            'kpi_name',         # KPIëª…
            'ì„±ê³¼ì§€í‘œëª…',        # í•œê¸€ ì„±ê³¼ì§€í‘œëª…
            'ê³¼ì œëª…',           # í•œê¸€ ê³¼ì œëª…
            'ëª©í‘œëª…',           # í•œê¸€ ëª©í‘œëª…
            'objective',        # ëª©ì 
            'goal',            # ëª©í‘œ
            'task'             # ê³¼ì œ
        ]
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ê³¼ ë§¤ì¹­
        goal_key = None
        for keyword in goal_keywords:
            # ì •í™•í•œ ë§¤ì¹­ ìš°ì„ 
            if keyword in first_record:
                goal_key = keyword
                logger.info(f"ëª©í‘œ ì»¬ëŸ¼ ë°œê²¬ (ì •í™•í•œ ë§¤ì¹­): {goal_key}")
                break
        
        # ì •í™•í•œ ë§¤ì¹­ì´ ì—†ìœ¼ë©´ ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
        if not goal_key:
            for keyword in goal_keywords:
                for actual_key in first_record.keys():
                    if keyword.lower() in str(actual_key).lower():
                        goal_key = actual_key
                        logger.info(f"ëª©í‘œ ì»¬ëŸ¼ ë°œê²¬ (ë¶€ë¶„ ë§¤ì¹­): {goal_key} (í‚¤ì›Œë“œ: {keyword})")
                        break
                if goal_key:
                    break
        
        if not goal_key:
            logger.error(f"ëª©í‘œ ê´€ë ¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(first_record.keys())}")
            return []
        
        # ëª©í‘œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
        categories = []
        for record in team_goals:
            goal_value = record.get(goal_key)
            if goal_value:
                goal_str = str(goal_value).strip()
                # ìœ íš¨í•œ ëª©í‘œëª…ì¸ì§€ í™•ì¸
                if (goal_str and 
                    goal_str.lower() not in ['nan', 'null', 'none', ''] and
                    len(goal_str) > 1):  # ìµœì†Œ 2ê¸€ì ì´ìƒ
                    categories.append(goal_str)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_categories = sorted(list(set(categories)))
        
        logger.info(f"ì¶”ì¶œëœ íŒ€ ëª©í‘œ ì¹´í…Œê³ ë¦¬ ({len(unique_categories)}ê°œ): {unique_categories}")
        
        if not unique_categories:
            logger.warning("ìœ íš¨í•œ íŒ€ ëª©í‘œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
        return unique_categories
    
    def execute_evaluation(self, prompt):
        """LLM í‰ê°€ ì‹¤í–‰"""
        try:
            logger.info(f"LLM í‰ê°€ ì‹¤í–‰ - ëª¨ë¸: {self.model}")
            print(f"ğŸ¤– OpenAI API í˜¸ì¶œ ì¤‘...")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ HR í‰ê°€ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  êµ¬ì²´ì ì¸ ì„±ê³¼ í‰ê°€ë¥¼ ì œê³µí•˜ë©°, í•­ìƒ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=4000
            )
            
            response_text = response.choices[0].message.content
            print(f"âœ… OpenAI API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
            
            # JSON ì¶”ì¶œ ë° íŒŒì‹±
            json_text = self._extract_json(response_text)
            result = json.loads(json_text)
            
            logger.info("LLM í‰ê°€ ì™„ë£Œ")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "error": "JSON íŒŒì‹± ì‹¤íŒ¨",
                "raw_response": response_text if 'response_text' in locals() else "No response",
                "error_details": str(e)
            }
        except Exception as e:
            logger.error(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            print(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def _extract_json(self, response_text):
        """ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ ì¶”ì¶œ"""
        if "```json" in response_text:
            json_start = response_text.find("```json") + 7
            json_end = response_text.find("```", json_start)
            return response_text[json_start:json_end].strip()
        else:
            return response_text.strip()

# =====================================
# ë©”ì¸ í‰ê°€ í´ë˜ìŠ¤
class WeeklyReportEvaluator:
    def __init__(self, config=None):
        self.config = config or Config()
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¤‘...")
        self.db_manager = DatabaseManager(self.config.DB_CONFIG)
        
        print("ğŸ” Pinecone ì—°ê²° ì¤‘...")
        self.pinecone_manager = PineconeManager(
            self.config.PINECONE_API_KEY, 
            self.config.PINECONE_INDEX_NAME
        )
        
        print("ğŸ¤– LLM ì´ˆê¸°í™” ì¤‘...")
        self.llm_evaluator = LLMEvaluator(
            self.config.OPENAI_API_KEY, 
            self.config.MODEL
        )
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_path = Path(self.config.OUTPUT_PATH)
        self.output_path.mkdir(exist_ok=True)
        
        logger.info("WeeklyReportEvaluator ì´ˆê¸°í™” ì™„ë£Œ")
    
    def evaluate_single_user(self, user_id):
        """ë‹¨ì¼ ì‚¬ìš©ì í‰ê°€ - ë¶„ê¸°ë³„ë¡œ ë¶„í• """
        logger.info(f"ì‚¬ìš©ì {user_id} ë¶„ê¸°ë³„ í‰ê°€ ì‹œì‘")
        
        try:
            # 1. ë°ì´í„° ë¡œë“œ
            team_criteria, team_goals = self.db_manager.load_team_data()
            search_results = self.pinecone_manager.search_user_data(user_id)
            
            if not search_results.matches:
                raise ValueError(f"ì‚¬ìš©ì {user_id}ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # 2. ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ê¸°ë³„ ë¶„í• 
            weekly_data = DataProcessor.convert_pinecone_to_dataframe(search_results)
            quarterly_data = DataProcessor.split_data_by_quarters(weekly_data)
            
            if not quarterly_data:
                raise ValueError(f"ì‚¬ìš©ì {user_id}ì˜ ìœ íš¨í•œ ë¶„ê¸°ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # 3. ê° ë¶„ê¸°ë³„ë¡œ í‰ê°€ ìˆ˜í–‰
            quarterly_results = {}
            
            for quarter_key, quarter_info in quarterly_data.items():
                print(f"ğŸ“Š {quarter_key} í‰ê°€ ì¤‘...")
                
                quarter_df = quarter_info['dataframe']
                year = quarter_info['year']
                quarter = quarter_info['quarter']
                
                # ë¶„ê¸°ë³„ ì§ì› ì •ë³´ ì¶”ì¶œ
                employee_info = DataProcessor.extract_employee_info_for_quarter(
                    quarter_df, year, quarter
                )
                
                if not employee_info:
                    logger.warning(f"ì‚¬ìš©ì {user_id}ì˜ {quarter_key} ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
                    continue
                
                # íŒ€ ë°ì´í„° í•„í„°ë§
                org_keywords = ['organization_id', 'org_id', 'team_id', 'ì¡°ì§', 'íŒ€']
                filtered_goals = DataProcessor.filter_team_data_by_org(
                    team_goals, employee_info['organization_id'], org_keywords
                )
                filtered_criteria = DataProcessor.filter_team_data_by_org(
                    team_criteria, employee_info['organization_id'], org_keywords
                )
                
                # LLM í‰ê°€
                prompt = self.llm_evaluator.generate_prompt(
                    employee_info, filtered_goals, filtered_criteria
                )
                evaluation_result = self.llm_evaluator.execute_evaluation(prompt)
                
                # ë¶„ê¸°ë³„ ê²°ê³¼ ì €ì¥
                if "error" not in evaluation_result:
                    output_file = self._save_quarterly_results(
                        evaluation_result, user_id, employee_info, year, quarter,
                        quarter_info['start_date'], quarter_info['end_date']
                    )
                    quarterly_results[quarter_key] = {
                        "status": "success",
                        "output_file": output_file,
                        "year": year,
                        "quarter": quarter
                    }
                    print(f"âœ… {quarter_key} í‰ê°€ ì™„ë£Œ")
                else:
                    quarterly_results[quarter_key] = {
                        "status": "failed",
                        "error": evaluation_result.get("error"),
                        "year": year,
                        "quarter": quarter
                    }
                    print(f"âŒ {quarter_key} í‰ê°€ ì‹¤íŒ¨: {evaluation_result.get('error')}")
            
            logger.info(f"ì‚¬ìš©ì {user_id} ë¶„ê¸°ë³„ í‰ê°€ ì™„ë£Œ - {len(quarterly_results)}ê°œ ë¶„ê¸°")
            return {
                "user_id": user_id,
                "quarterly_results": quarterly_results,
                "total_quarters": len(quarterly_results),
                "successful_quarters": len([r for r in quarterly_results.values() if r["status"] == "success"])
            }
                
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì {user_id} í‰ê°€ ì‹¤íŒ¨: {e}")
            return {"error": str(e), "user_id": user_id}
    
    def evaluate_batch_users(self, user_ids=None):
        """ë°°ì¹˜ ì‚¬ìš©ì í‰ê°€ - ë¶„ê¸°ë³„ ì²˜ë¦¬"""
        logger.info("ë°°ì¹˜ ë¶„ê¸°ë³„ í‰ê°€ ì‹œì‘")
        
        if user_ids is None:
            user_ids = self.pinecone_manager.get_available_user_ids()
        
        if not user_ids:
            return {"error": "ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        # ìˆ˜ì •ëœ batch_results êµ¬ì¡°
        batch_results = {
            "batch_metadata": {
                "start_time": datetime.now().isoformat(),
                "target_user_ids": user_ids,
                "total_users": len(user_ids)
            },
            "individual_results": {},  # ì´ í‚¤ê°€ ëˆ„ë½ë˜ì–´ ìˆì—ˆìŒ
            "batch_summary": {
                "successful_users": 0,
                "failed_users": 0,
                "total_quarters_processed": 0,
                "successful_quarters": 0,
                "failed_quarters": 0
            }
        }
        
        for i, user_id in enumerate(user_ids, 1):
            print(f"\nğŸ“Š ë°°ì¹˜ í‰ê°€ ì§„í–‰: {i}/{len(user_ids)} - User {user_id}")
            
            result = self.evaluate_single_user(user_id)
            batch_results["individual_results"][user_id] = result
            
            if "error" not in result:
                batch_results["batch_summary"]["successful_users"] += 1
                batch_results["batch_summary"]["total_quarters_processed"] += result.get("total_quarters", 0)
                batch_results["batch_summary"]["successful_quarters"] += result.get("successful_quarters", 0)
                batch_results["batch_summary"]["failed_quarters"] += (
                    result.get("total_quarters", 0) - result.get("successful_quarters", 0)
                )
                
                print(f"âœ… User {user_id} í‰ê°€ ì„±ê³µ - {result.get('successful_quarters', 0)}/{result.get('total_quarters', 0)} ë¶„ê¸°")
            else:
                batch_results["batch_summary"]["failed_users"] += 1
                print(f"âŒ User {user_id} í‰ê°€ ì‹¤íŒ¨: {result['error']}")
        
        batch_results["batch_metadata"]["end_time"] = datetime.now().isoformat()
        
        # ë°°ì¹˜ ê²°ê³¼ ì €ì¥
        self._save_batch_results(batch_results)
        
        logger.info(f"ë°°ì¹˜ í‰ê°€ ì™„ë£Œ - ì„±ê³µ ì‚¬ìš©ì: {batch_results['batch_summary']['successful_users']}ëª…, "
                   f"ì„±ê³µ ë¶„ê¸°: {batch_results['batch_summary']['successful_quarters']}ê°œ")
        return batch_results
    
    def _save_quarterly_results(self, results, user_id, employee_info, year, quarter, quarter_start, quarter_end):
        """ë¶„ê¸°ë³„ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"evaluation_{user_id}_{year}Q{quarter}_{timestamp}.json"
        
        # í˜„ì¬ ë‚ ì§œ
        current_date = datetime.now().strftime("%Y-%m-%d")
        
        # ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ
        user_name = employee_info.get('name', f"User_{user_id}")
        org_id = employee_info.get('organization_id', '')
        
        # ì‹¤ì œ ì¡°ì§ëª…ì„ DBì—ì„œ ì¡°íšŒ
        if org_id:
            department = self.db_manager.get_organization_name(org_id)
        else:
            department = "ë¯¸ì§€ì • íŒ€"
        
        # ë¶„ê¸°ë³„ JSON êµ¬ì¡° ìƒì„±
        final_results = {
            "type": "personal-quarter",
            "evaluated_year": int(year),
            "evaluated_quarter": int(quarter),
            "created_at": current_date,
            "title": f"{year} {quarter}ë¶„ê¸° ì„±ê³¼ ë¦¬í¬íŠ¸",
            "startDate": quarter_start,
            "endDate": quarter_end,
            "user": {
                "userId": int(user_id),
                "name": user_name,
                "department": department
            }
        }
        
        # í‰ê°€ ê²°ê³¼ ì¶”ê°€
        if "teamGoals" in results:
            final_results["teamGoals"] = results["teamGoals"]
        elif "error" not in results:
            final_results.update(results)
        else:
            final_results["error"] = results.get("error")
            final_results["error_details"] = results.get("error_details")
        
        # ì°¸ì¡° ì •ë³´ ì¶”ê°€
        final_results["reference"] = {
            "evaluation_timestamp": datetime.now().isoformat(),
            "user_id": user_id,
            "organization_info": {
                "organization_id": org_id,
                "organization_name": department
            },
            "quarter_info": {
                "year": year,
                "quarter": quarter,
                "total_weeks": employee_info.get('total_weeks', 0),
                "total_activities": employee_info.get('total_activities', 0)
            },
            "data_sources": {
                "weekly_data": f"Pinecone Index: {self.config.PINECONE_INDEX_NAME}",
                "team_data": f"MariaDB: {self.config.DB_CONFIG['host']}/{self.config.DB_CONFIG['database']}",
                "organization_data": "MariaDB.organizations"
            }
        }
        
        output_file = self.output_path / filename
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ë¶„ê¸°ë³„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file} (íŒ€: {department})")
        return str(output_file)
    
    def _save_batch_results(self, batch_results):
        """ë°°ì¹˜ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"batch_evaluation_{timestamp}.json"
        
        # ë°°ì¹˜ ê²°ê³¼ì—ë„ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        current_date = datetime.now().strftime("%Y-%m-%d")
        
        final_batch_results = {
            "type": "batch-evaluation",
            "evaluated_year": 2024,
            "evaluated_quarter": 4,
            "created_at": current_date,
            "title": "2024 4ë¶„ê¸° ë°°ì¹˜ ì„±ê³¼ í‰ê°€",
            "startDate": "2024-10-07",
            "endDate": "2024-12-27"
        }
        
        # ê¸°ì¡´ ë°°ì¹˜ ê²°ê³¼ ì¶”ê°€
        final_batch_results.update(batch_results)
        
        output_file = self.output_path / filename
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_batch_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ë°°ì¹˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")

# =====================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ¯ === ì£¼ê°„ ë³´ê³ ì„œ ë¶„ê¸°ë³„ ë°°ì¹˜ í‰ê°€ ì‹œìŠ¤í…œ ===")
    print("ğŸ“‹ Pinecone + MariaDB ê¸°ë°˜ AI í‰ê°€ ì‹œìŠ¤í…œ")
    print("ğŸ”„ ê° ì‚¬ìš©ìë³„ë¡œ ë¶„ê¸°ë‹¹ 1ê°œì”© JSON íŒŒì¼ ìƒì„±")
    
    try:
        print("\nğŸ¤– ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        print("ğŸ“‹ í™˜ê²½ë³€ìˆ˜ ê²€ì¦ ì¤‘...")
        
        # Config ì´ˆê¸°í™” ì‹œ í™˜ê²½ë³€ìˆ˜ ê²€ì¦ì´ ìë™ìœ¼ë¡œ ì´ë£¨ì–´ì§
        evaluator = WeeklyReportEvaluator()
        print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        
        while True:
            print("\nğŸ¯ === ë©”ì¸ ë©”ë‰´ ===")
            print("1. ë¶„ê¸°ë³„ ë°°ì¹˜ í‰ê°€ (ëª¨ë“  ì‚¬ìš©ì)")
            print("2. ì¢…ë£Œ")
            
            choice = input("\nì„ íƒí•˜ì„¸ìš” (1-2): ").strip()
            
            if choice == "1":
                # ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ìš©ì í™•ì¸
                print("\nğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ìš©ì ì¡°íšŒ ì¤‘...")
                available_users = evaluator.pinecone_manager.get_available_user_ids()
                
                if not available_users:
                    print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                print(f"\nğŸ“Š ì´ {len(available_users)}ëª…ì˜ ì‚¬ìš©ì ë¶„ê¸°ë³„ ë°°ì¹˜ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
                print(f"ğŸ“‹ ëŒ€ìƒ ì‚¬ìš©ì: {available_users}")
                print(f"â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ {len(available_users) * 3}ë¶„")
                print(f"ğŸ“ ê° ì‚¬ìš©ìë³„ë¡œ ë¶„ê¸°ë‹¹ 1ê°œì”© JSON íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.")
                
                confirm = input("\nê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
                
                if confirm not in ['y', 'yes']:
                    print("âŒ ë°°ì¹˜ í‰ê°€ë¥¼ ì·¨ì†Œí•©ë‹ˆë‹¤.")
                    continue
                
                print(f"\nğŸš€ ë¶„ê¸°ë³„ ë°°ì¹˜ í‰ê°€ ì‹œì‘...")
                print(f"ğŸ’¡ ê° ì‚¬ìš©ìì˜ ë°ì´í„°ë¥¼ ë¶„ê¸°ë³„ë¡œ ë¶„í• í•˜ì—¬ ê°œë³„ í‰ê°€í•©ë‹ˆë‹¤.")
                
                batch_result = evaluator.evaluate_batch_users()
                
                if "error" not in batch_result:
                    print(f"\nğŸ‰ === ë¶„ê¸°ë³„ ë°°ì¹˜ í‰ê°€ ì™„ë£Œ ===")
                    print(f"ğŸ“Š ì´ ëŒ€ìƒ ì‚¬ìš©ì: {batch_result['batch_metadata']['total_users']}ëª…")
                    print(f"âœ… ì„±ê³µí•œ ì‚¬ìš©ì: {batch_result['batch_summary']['successful_users']}ëª…")
                    print(f"âŒ ì‹¤íŒ¨í•œ ì‚¬ìš©ì: {batch_result['batch_summary']['failed_users']}ëª…")
                    
                    # ë¶„ê¸°ë³„ í†µê³„
                    print(f"\nğŸ“ˆ ë¶„ê¸°ë³„ í†µê³„:")
                    print(f"   ğŸ“Š ì´ ì²˜ë¦¬ëœ ë¶„ê¸°: {batch_result['batch_summary']['total_quarters_processed']}ê°œ")
                    print(f"   âœ… ì„±ê³µí•œ ë¶„ê¸°: {batch_result['batch_summary']['successful_quarters']}ê°œ")
                    print(f"   âŒ ì‹¤íŒ¨í•œ ë¶„ê¸°: {batch_result['batch_summary']['failed_quarters']}ê°œ")
                    
                    # ì„±ê³µë¥  ê³„ì‚°
                    total_users = batch_result['batch_metadata']['total_users']
                    success_users = batch_result['batch_summary']['successful_users']
                    total_quarters = batch_result['batch_summary']['total_quarters_processed']
                    success_quarters = batch_result['batch_summary']['successful_quarters']
                    
                    if total_users > 0:
                        user_success_rate = (success_users / total_users * 100)
                        print(f"   ğŸ“ˆ ì‚¬ìš©ì ì„±ê³µë¥ : {user_success_rate:.1f}%")
                    
                    if total_quarters > 0:
                        quarter_success_rate = (success_quarters / total_quarters * 100)
                        print(f"   ğŸ“ˆ ë¶„ê¸° ì„±ê³µë¥ : {quarter_success_rate:.1f}%")
                    
                    # ì‹œê°„ ì •ë³´
                    start_time = batch_result['batch_metadata']['start_time']
                    end_time = batch_result['batch_metadata']['end_time']
                    print(f"\nğŸ•’ ì‹œì‘: {start_time}")
                    print(f"ğŸ•’ ì¢…ë£Œ: {end_time}")
                    
                    # ì‹¤íŒ¨í•œ ì‚¬ìš©ì ìƒì„¸ ì •ë³´
                    failed_users = []
                    for user_id, result in batch_result['individual_results'].items():
                        if "error" in result:
                            failed_users.append(user_id)
                    
                    if failed_users:
                        print(f"\nâŒ ì‹¤íŒ¨í•œ ì‚¬ìš©ì:")
                        for user_id in failed_users:
                            error_msg = batch_result['individual_results'][user_id].get('error', 'Unknown error')
                            print(f"   - User {user_id}: {error_msg}")
                    
                    # ì„±ê³µí•œ ì‚¬ìš©ìì˜ ë¶„ê¸°ë³„ ìƒì„¸ ì •ë³´
                    successful_details = []
                    for user_id, result in batch_result['individual_results'].items():
                        if "error" not in result and "quarterly_results" in result:
                            quarterly_info = result["quarterly_results"]
                            success_count = sum(1 for q in quarterly_info.values() if q["status"] == "success")
                            total_count = len(quarterly_info)
                            successful_details.append(f"User {user_id}: {success_count}/{total_count} ë¶„ê¸°")
                    
                    if successful_details:
                        print(f"\nğŸ“‹ ì‚¬ìš©ìë³„ ë¶„ê¸° ì„±ê³µ í˜„í™©:")
                        for detail in successful_details:
                            print(f"   - {detail}")
                    
                    print(f"\nğŸ“ ê²°ê³¼ íŒŒì¼ì´ '{evaluator.config.OUTPUT_PATH}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    print(f"ğŸ’¡ íŒŒì¼ëª… í˜•ì‹: evaluation_{{ì‚¬ìš©ìID}}_{{ë…„ë„}}Q{{ë¶„ê¸°}}_{{íƒ€ì„ìŠ¤íƒ¬í”„}}.json")
                    print(f"ğŸ“„ ì˜ˆì‹œ: evaluation_100_2024Q1_20250625_153054.json")
                    
                else:
                    print(f"âŒ ë°°ì¹˜ í‰ê°€ ì‹¤íŒ¨: {batch_result['error']}")
            
            elif choice == "2":
                print("ğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1-2 ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
    except ValueError as e:
        # í™˜ê²½ë³€ìˆ˜ ê´€ë ¨ ì˜¤ë¥˜
        print(f"âŒ ì„¤ì • ì˜¤ë¥˜: {e}")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("1. .env íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸")
        print("2. í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ë“¤ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸")
        print("3. API í‚¤ë“¤ì´ ìœ íš¨í•œì§€ í™•ì¸")
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ë©”ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        
        # ì—ëŸ¬ ìƒì„¸ ì •ë³´ í‘œì‹œ
        import traceback
        print(f"\nğŸ“‹ ì—ëŸ¬ ìƒì„¸:")
        traceback.print_exc()


if __name__ == "__main__":
    main()