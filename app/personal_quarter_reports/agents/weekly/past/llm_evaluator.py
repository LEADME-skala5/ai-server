class WeeklyReportEvaluator:
    def __init__(self, config=None):
        self.config = config or Config()
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¤‘...")
        self.db_manager = DatabaseManager(self.config.DB_CONFIG)
        
        print("ğŸ” Pinecone ì—°ê²° ì¤‘...")
        self.pinecone_manager = PineconeManager(
            self.config.PINECONE_API_KEY, 
            self.config.PINECONE_INDEX_NAME
        )
        
        print("ğŸ¤– LLM ì´ˆê¸°í™” ì¤‘...")
        self.llm_evaluator = LLMEvaluator(
            self.config.OPENAI_API_KEY, 
            self.config.MODEL
        )
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_path = Path(self.config.OUTPUT_PATH)
        self.output_path.mkdir(exist_ok=True)
        
        # ìƒíƒœ ê´€ë¦¬
        self.evaluation_history = []
        
        logger.info("WeeklyReportEvaluator ì´ˆê¸°í™” ì™„ë£Œ")
    
    def validate_system(self, user_id=None):
        """ì‹œìŠ¤í…œ ì „ì²´ ê²€ì¦"""
        logger.info("ì‹œìŠ¤í…œ ê²€ì¦ ì‹œì‘")
        
        validation_result = {
            "valid": True,
            "errors": [],
            "warnings": []
        }
        
        try:
            # MariaDB ê²€ì¦
            print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ ì¤‘...")
            db_validation = self.db_manager.validate_tables()
            validation_result["mariadb"] = db_validation
            
            # Pinecone ê²€ì¦
            print("ğŸ” Pinecone ê²€ì¦ ì¤‘...")
            pinecone_validation = self.pinecone_manager.validate_connection(user_id)
            validation_result["pinecone"] = pinecone_validation
            
            logger.info("ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ")
            
        except Exception as e:
            validation_result["valid"] = False
            validation_result["errors"].append(str(e))
            logger.error(f"ì‹œìŠ¤í…œ ê²€ì¦ ì‹¤íŒ¨: {e}")
        
        return validation_result
    
    def evaluate_single_user(self, user_id):
        """ë‹¨ì¼ ì‚¬ìš©ì í‰ê°€"""
        logger.info(f"ì‚¬ìš©ì {user_id} í‰ê°€ ì‹œì‘")
        
        try:
            # 1. ì‹œìŠ¤í…œ ê²€ì¦
            print(f"1ï¸âƒ£ ì‹œìŠ¤í…œ ê²€ì¦ ì¤‘...")
            validation = self.validate_system(user_id)
            if not validation["valid"]:
                raise ValueError(f"ì‹œìŠ¤í…œ ê²€ì¦ ì‹¤íŒ¨: {validation['errors']}")
            
            # 2. ë°ì´í„° ë¡œë“œ
            print(f"2ï¸âƒ£ ë°ì´í„° ë¡œë“œ ì¤‘...")
            team_criteria, team_goals = self.db_manager.load_team_data()
            search_results = self.pinecone_manager.search_user_data(user_id)
            
            if not search_results.matches:
                raise ValueError(f"ì‚¬ìš©ì {user_id}ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # 3. ë°ì´í„° ì²˜ë¦¬
            print(f"3ï¸âƒ£ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
            weekly_data = DataProcessor.convert_pinecone_to_dataframe(search_results)
            employee_info = DataProcessor.extract_employee_info(weekly_data)
            
            # ì£¼ê°„ ì—…ë¬´ ë°ì´í„° ì¶”ê°€
            employee_info['weekly_tasks'] = weekly_data[['start_date', 'end_date', 'done_task']].to_dict('records')
            
            # íŒ€ ë°ì´í„° í•„í„°ë§
            org_keywords = ['organization_id', 'org_id', 'team_id', 'ì¡°ì§', 'íŒ€']
            filtered_goals = DataProcessor.filter_team_data_by_org(
                team_goals, employee_info['organization_id'], org_keywords
            )
            filtered_criteria = DataProcessor.filter_team_data_by_org(
                team_criteria, employee_info['organization_id'], org_keywords
            )
            
            # 4. LLM í‰ê°€
            print(f"4ï¸âƒ£ AI í‰ê°€ ì‹¤í–‰ ì¤‘...")
            prompt = self.llm_evaluator.generate_prompt(
                employee_info, filtered_goals, filtered_criteria
            )
            evaluation_result = self.llm_evaluator.execute_evaluation(prompt)
            
            # 5. ê²°ê³¼ ì €ì¥
            if "error" not in evaluation_result:
                print(f"5ï¸âƒ£ ê²°ê³¼ ì €ì¥ ì¤‘...")
                output_file = self._save_results(evaluation_result, user_id)
                
                self.evaluation_history.append({
                    "user_id": user_id,
                    "timestamp": datetime.now().isoformat(),
                    "output_file": output_file,
                    "status": "success"
                })
                
                logger.info(f"ì‚¬ìš©ì {user_id} í‰ê°€ ì™„ë£Œ")
                return evaluation_result
            else:
                raise ValueError(f"LLM í‰ê°€ ì‹¤íŒ¨: {evaluation_result['error']}")
                
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì {user_id} í‰ê°€ ì‹¤íŒ¨: {e}")
            return {"error": str(e), "user_id": user_id}
    
    def evaluate_batch_users(self, user_ids=None):
        """ë°°ì¹˜ ì‚¬ìš©ì í‰ê°€"""
        logger.info("ë°°ì¹˜ í‰ê°€ ì‹œì‘")
        
        if user_ids is None:
            user_ids = self.pinecone_manager.get_available_user_ids()
        
        if not user_ids:
            return {"error": "ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        batch_results = {
            "batch_metadata": {
                "start_time": datetime.now().isoformat(),
                "target_user_ids": user_ids,
                "total_users": len(user_ids)
            },
            "individual_results": {},
            "batch_summary": {
                "successful_evaluations": 0,
                "failed_evaluations": 0
            }
        }
        
        for i, user_id in enumerate(user_ids, 1):
            print(f"\nğŸ“Š ë°°ì¹˜ í‰ê°€ ì§„í–‰: {i}/{len(user_ids)} - User {user_id}")
            
            result = self.evaluate_single_user(user_id)
            batch_results["individual_results"][user_id] = result
            
            if "error" not in result:
                batch_results["batch_summary"]["successful_evaluations"] += 1
                print(f"âœ… User {user_id} í‰ê°€ ì„±ê³µ")
            else:
                batch_results["batch_summary"]["failed_evaluations"] += 1
                print(f"âŒ User {user_id} í‰ê°€ ì‹¤íŒ¨: {result['error']}")
        
        batch_results["batch_metadata"]["end_time"] = datetime.now().isoformat()
        
        # ë°°ì¹˜ ê²°ê³¼ ì €ì¥
        self._save_batch_results(batch_results)
        
        logger.info(f"ë°°ì¹˜ í‰ê°€ ì™„ë£Œ - ì„±ê³µ: {batch_results['batch_summary']['successful_evaluations']}ëª…")
        return batch_results
    
    def get_available_users(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ"""
        return self.pinecone_manager.get_available_user_ids()
    
    def get_evaluation_statistics(self):
        """í‰ê°€ í†µê³„ ì¡°íšŒ"""
        if not self.evaluation_history:
            return {"total_evaluations": 0}
        
        successful = [e for e in self.evaluation_history if e.get("status") == "success"]
        
        return {
            "total_evaluations": len(self.evaluation_history),
            "successful_evaluations": len(successful),
            "failed_evaluations": len(self.evaluation_history) - len(successful),
            "latest_evaluation": self.evaluation_history[-1]["timestamp"],
            "evaluated_users": [e["user_id"] for e in self.evaluation_history]
        }
    
    def _save_results(self, results, user_id):
        """ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"evaluation_{user_id}_{timestamp}.json"
        
        # ì°¸ì¡° ì •ë³´ ì¶”ê°€
        results["reference"] = {
            "evaluation_timestamp": datetime.now().isoformat(),
            "user_id": user_id,
            "data_sources": {
                "weekly_data": f"Pinecone Index: {self.config.PINECONE_INDEX_NAME}",
                "team_data": f"MariaDB: {self.config.DB_CONFIG['host']}/{self.config.DB_CONFIG['database']}"
            }
        }
        
        output_file = self.output_path / filename
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        return str(output_file)
    
    def _save_batch_results(self, batch_results):
        """ë°°ì¹˜ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"batch_evaluation_{timestamp}.json"
        
        output_file = self.output_path / filename
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(batch_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ë°°ì¹˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")