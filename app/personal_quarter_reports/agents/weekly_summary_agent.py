import pandas as pd
import json
import openai
from typing import Dict, List, Any, Optional, Tuple
import os
from datetime import datetime
from pathlib import Path
import logging

# .env íŒŒì¼ ì§€ì› (ì„ íƒì‚¬í•­)
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ë¬´ì‹œ

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class WeeklyReportEvaluationAgent:
    def __init__(self, 
                 api_key: Optional[str] = None, 
                 model: str = "gpt-4-turbo",
                 base_data_path: str = "./data",
                 output_path: str = "./output"):
        """
        AI ê¸°ë°˜ ì£¼ê°„ ë³´ê³ ì„œ í‰ê°€ ì—ì´ì „íŠ¸
        
        Args:
            api_key: OpenAI API í‚¤ (í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¡œë„ ì„¤ì • ê°€ëŠ¥)
            model: ì‚¬ìš©í•  LLM ëª¨ë¸ëª…
            base_data_path: ë°ì´í„° íŒŒì¼ë“¤ì´ ìœ„ì¹˜í•œ ê¸°ë³¸ ê²½ë¡œ
            output_path: ê²°ê³¼ íŒŒì¼ë“¤ì„ ì €ì¥í•  ê²½ë¡œ
        """
        # API í‚¤ ì„¤ì • - ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì‹œë„
        final_api_key = api_key or os.getenv("OPENAI_API_KEY")
        
        if not final_api_key:
            raise ValueError(
                "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                "ë‹¤ìŒ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:\n"
                "1. í™˜ê²½ë³€ìˆ˜: set OPENAI_API_KEY=your-key (Windows)\n"
                "2. .env íŒŒì¼: OPENAI_API_KEY=your-key\n"
                "3. ì½”ë“œì—ì„œ ì§ì ‘ ì „ë‹¬: WeeklyReportEvaluationAgent(api_key='your-key')"
            )
        
        self.client = openai.OpenAI(api_key=final_api_key)
        self.model = model
        self.base_data_path = Path(base_data_path)
        self.output_path = Path(output_path)
        
        # ë°ì´í„° ì €ì¥ì†Œ
        self.weekly_data = None
        self.team_criteria = None
        self.team_goals = None
        
        # ì—ì´ì „íŠ¸ ìƒíƒœ ì¶”ì 
        self.evaluation_history = []
        self.current_context = {}
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_path.mkdir(exist_ok=True)
        
        logger.info(f"WeeklyReportEvaluationAgent ì´ˆê¸°í™” ì™„ë£Œ - ëª¨ë¸: {model}")
        
    def plan_evaluation(self, 
                       weekly_file: str = "weekly.csv",
                       criteria_file: str = "team_criteria.csv", 
                       goals_file: str = "team_goal.csv",
                       target_employees: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        í‰ê°€ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.
        """
        logger.info("=== í‰ê°€ ê³„íš ìˆ˜ë¦½ ì‹œì‘ ===")
        
        plan = {
            "timestamp": datetime.now().isoformat(),
            "data_files": {
                "weekly": weekly_file,
                "criteria": criteria_file,
                "goals": goals_file
            },
            "target_employees": target_employees,
            "steps": []
        }
        
        # 1ë‹¨ê³„: ë°ì´í„° ê²€ì¦
        plan["steps"].append({
            "step": 1,
            "action": "ë°ì´í„° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë° êµ¬ì¡° ê²€ì¦",
            "status": "planned"
        })
        
        # 2ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        plan["steps"].append({
            "step": 2,
            "action": "CSV íŒŒì¼ ë¡œë“œ ë° ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬",
            "status": "planned"
        })
        
        # 3ë‹¨ê³„: í‰ê°€ ëŒ€ìƒ ë¶„ì„
        plan["steps"].append({
            "step": 3,
            "action": "í‰ê°€ ëŒ€ìƒ ì§ì› ë° íŒ€ êµ¬ì¡° ë¶„ì„",
            "status": "planned"
        })
        
        # 4ë‹¨ê³„: í‰ê°€ ì‹¤í–‰
        plan["steps"].append({
            "step": 4,
            "action": "ê°œë³„ ì§ì› í‰ê°€ ìˆ˜í–‰",
            "status": "planned"
        })
        
        # 5ë‹¨ê³„: ê²°ê³¼ ê²€ì¦ ë° ì €ì¥
        plan["steps"].append({
            "step": 5,
            "action": "í‰ê°€ ê²°ê³¼ ê²€ì¦ ë° íŒŒì¼ ì €ì¥",
            "status": "planned"
        })
        
        self.current_context["plan"] = plan
        logger.info(f"í‰ê°€ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ - {len(plan['steps'])}ë‹¨ê³„")
        
        return plan
    
    def validate_data_files(self, 
                           weekly_file: str,
                           criteria_file: str, 
                           goals_file: str) -> Dict[str, Any]:
        """
        ë°ì´í„° íŒŒì¼ë“¤ì˜ ì¡´ì¬ ì—¬ë¶€ì™€ êµ¬ì¡°ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
        """
        logger.info("ë°ì´í„° íŒŒì¼ ê²€ì¦ ì‹œì‘")
        
        validation_result = {
            "valid": True,
            "errors": [],
            "warnings": [],
            "file_info": {}
        }
        
        files_to_check = {
            "weekly": weekly_file,
            "criteria": criteria_file,
            "goals": goals_file
        }
        
        for file_type, filename in files_to_check.items():
            file_path = self.base_data_path / filename
            
            if not file_path.exists():
                validation_result["errors"].append(f"{file_type} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
                validation_result["valid"] = False
                continue
                
            try:
                # íŒŒì¼ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
                df = pd.read_csv(file_path)
                validation_result["file_info"][file_type] = {
                    "path": str(file_path),
                    "rows": len(df),
                    "columns": list(df.columns),
                    "size_mb": file_path.stat().st_size / (1024 * 1024)
                }
                
                # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
                if file_type == "weekly":
                    required_cols = ["employee_number", "done_task"]
                    missing_cols = [col for col in required_cols if col not in df.columns]
                    if missing_cols:
                        validation_result["errors"].append(
                            f"weekly íŒŒì¼ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_cols}"
                        )
                        validation_result["valid"] = False
                        
            except Exception as e:
                validation_result["errors"].append(f"{file_type} íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
                validation_result["valid"] = False
        
        if validation_result["valid"]:
            logger.info("ëª¨ë“  ë°ì´í„° íŒŒì¼ ê²€ì¦ ì„±ê³µ")
        else:
            logger.error(f"ë°ì´í„° íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {validation_result['errors']}")
            
        return validation_result
    
    def load_and_preprocess_data(self, 
                                weekly_file: str,
                                criteria_file: str, 
                                goals_file: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        logger.info("ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì‹œì‘")
        
        try:
            self.weekly_data = pd.read_csv(self.base_data_path / weekly_file)
            self.team_criteria = pd.read_csv(self.base_data_path / criteria_file)
            self.team_goals = pd.read_csv(self.base_data_path / goals_file)
            
            # ë°ì´í„° ì „ì²˜ë¦¬
            preprocessing_result = {
                "weekly_records": len(self.weekly_data),
                "unique_employees": self.weekly_data['employee_number'].nunique() if 'employee_number' in self.weekly_data.columns else 0,
                "teams_in_goals": self._extract_teams_from_data(),
                "date_range": self._extract_date_range(),
                "data_quality": self._assess_data_quality()
            }
            
            logger.info(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ - ì§ì› {preprocessing_result['unique_employees']}ëª…, ê¸°ë¡ {preprocessing_result['weekly_records']}ê±´")
            return preprocessing_result
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise ValueError(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def _extract_teams_from_data(self) -> List[str]:
        """ë°ì´í„°ì—ì„œ íŒ€ ëª©ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        teams = set()
        
        # weekly ë°ì´í„°ì—ì„œ íŒ€ ì¶”ì¶œ
        if self.weekly_data is not None:
            team_columns = ['team', 'organization', 'ì¡°ì§', 'íŒ€']
            for col in team_columns:
                if col in self.weekly_data.columns:
                    teams.update(self.weekly_data[col].dropna().unique())
                    break
        
        # goals ë°ì´í„°ì—ì„œ íŒ€ ì¶”ì¶œ
        if self.team_goals is not None:
            team_column = self._find_column_by_keywords(
                self.team_goals, 
                ['team', 'org', 'group', 'dept', 'íŒ€', 'ì¡°ì§', 'ë¶€ì„œ']
            )
            if team_column:
                teams.update(self.team_goals[team_column].dropna().unique())
        
        return sorted(list(teams))
    
    def _extract_date_range(self) -> Dict[str, str]:
        """ë°ì´í„°ì˜ ë‚ ì§œ ë²”ìœ„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if self.weekly_data is None:
            return {}
            
        date_info = {}
        for date_col in ['start_date', 'finish_date', 'date']:
            if date_col in self.weekly_data.columns:
                dates = pd.to_datetime(self.weekly_data[date_col], errors='coerce').dropna()
                if not dates.empty:
                    date_info[f"{date_col}_min"] = dates.min().strftime('%Y-%m-%d')
                    date_info[f"{date_col}_max"] = dates.max().strftime('%Y-%m-%d')
        
        return date_info
    
    def _assess_data_quality(self) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤."""
        quality_report = {}
        
        if self.weekly_data is not None:
            quality_report["weekly"] = {
                "missing_employee_numbers": self.weekly_data['employee_number'].isnull().sum() if 'employee_number' in self.weekly_data.columns else 0,
                "missing_tasks": self.weekly_data['done_task'].isnull().sum() if 'done_task' in self.weekly_data.columns else 0,
                "duplicate_records": self.weekly_data.duplicated().sum(),
                "empty_task_content": (self.weekly_data['done_task'].str.strip() == '').sum() if 'done_task' in self.weekly_data.columns else 0
            }
        
        return quality_report
    
    def analyze_employee_data(self, employee_number: str) -> Dict[str, Any]:
        """
        íŠ¹ì • ì§ì›ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        logger.info(f"ì§ì› {employee_number} ë°ì´í„° ë¶„ì„ ì‹œì‘")
        
        if self.weekly_data is None:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        employee_data = self.weekly_data[
            self.weekly_data['employee_number'] == employee_number
        ].copy()
        
        if employee_data.empty:
            raise ValueError(f"ì§ì›ë²ˆí˜¸ {employee_number}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì§ì› ì •ë³´ ì¶”ì¶œ
        context = {
            "employee_info": self._extract_employee_info(employee_data),
            "team_goals": self._get_filtered_team_goals(employee_data),
            "team_criteria": self._get_filtered_team_criteria(employee_data),
            "weekly_tasks": employee_data[['start_date', 'finish_date', 'done_task']].to_dict('records') if all(col in employee_data.columns for col in ['start_date', 'finish_date', 'done_task']) else []
        }
        
        logger.info(f"ì§ì› {employee_number} ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
        return context
    
    def _extract_employee_info(self, employee_data: pd.DataFrame) -> Dict[str, Any]:
        """ì§ì› ê¸°ë³¸ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        info = {
            "name": employee_data['name'].iloc[0] if 'name' in employee_data.columns else "Unknown",
            "employee_number": employee_data['employee_number'].iloc[0],
            "department": employee_data['department'].iloc[0] if 'department' in employee_data.columns else "",
            "team": employee_data['team'].iloc[0] if 'team' in employee_data.columns else "",
            "period": "",
            "total_weeks": len(employee_data)
        }
        
        # ë‚ ì§œ ë²”ìœ„ ì„¤ì •
        if 'start_date' in employee_data.columns and 'finish_date' in employee_data.columns:
            start_dates = pd.to_datetime(employee_data['start_date'], errors='coerce').dropna()
            finish_dates = pd.to_datetime(employee_data['finish_date'], errors='coerce').dropna()
            if not start_dates.empty and not finish_dates.empty:
                info["period"] = f"{start_dates.min().strftime('%Y-%m-%d')} ~ {finish_dates.max().strftime('%Y-%m-%d')}"
        
        logger.info(f"ì§ì› ì •ë³´: {info['name']} ({info['department']} - {info['team']})")
        return info
    
    def _get_filtered_team_goals(self, employee_data: pd.DataFrame) -> List[Dict]:
        """í•´ë‹¹ ì§ì›ì˜ íŒ€ ëª©í‘œë§Œ í•„í„°ë§í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self.team_goals is None or self.team_goals.empty:
            return []
            
        employee_team = employee_data['team'].iloc[0] if 'team' in employee_data.columns else ""
        team_column = self._find_column_by_keywords(
            self.team_goals, 
            ['team', 'org', 'group', 'dept', 'íŒ€', 'ì¡°ì§', 'ë¶€ì„œ']
        )
        
        if team_column and employee_team:
            filtered_goals = self.team_goals[
                self.team_goals[team_column] == employee_team
            ].to_dict('records')
            logger.info(f"íŒ€ ëª©í‘œ í•„í„°ë§ ì™„ë£Œ: {len(filtered_goals)}ê°œ ëª©í‘œ")
            return filtered_goals
        else:
            logger.warning("íŒ€ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì „ì²´ ëª©í‘œ ë°˜í™˜")
            return self.team_goals.to_dict('records')
    
    def _get_filtered_team_criteria(self, employee_data: pd.DataFrame) -> List[Dict]:
        """í•´ë‹¹ ì§ì›ì˜ íŒ€ í‰ê°€ ê¸°ì¤€ë§Œ í•„í„°ë§í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self.team_criteria is None or self.team_criteria.empty:
            return []
            
        employee_team = employee_data['team'].iloc[0] if 'team' in employee_data.columns else ""
        team_column = self._find_column_by_keywords(
            self.team_criteria, 
            ['team', 'org', 'group', 'dept', 'íŒ€', 'ì¡°ì§', 'ë¶€ì„œ']
        )
        
        if team_column and employee_team:
            filtered_criteria = self.team_criteria[
                self.team_criteria[team_column] == employee_team
            ].to_dict('records')
            logger.info(f"íŒ€ ê¸°ì¤€ í•„í„°ë§ ì™„ë£Œ: {len(filtered_criteria)}ê°œ ê¸°ì¤€")
            return filtered_criteria
        else:
            logger.warning("íŒ€ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì „ì²´ ê¸°ì¤€ ë°˜í™˜")
            return self.team_criteria.to_dict('records')
    
    def _find_column_by_keywords(self, 
                                dataframe: pd.DataFrame, 
                                keywords: List[str]) -> Optional[str]:
        """í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì»¬ëŸ¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
        for col in dataframe.columns:
            col_lower = str(col).lower().strip()
            if any(keyword.lower() in col_lower for keyword in keywords):
                return col
        return None
    
    def extract_team_goal_categories(self, team_goals: List[Dict]) -> List[str]:
        """íŒ€ ëª©í‘œì—ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if not team_goals:
            logger.warning("íŒ€ ëª©í‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ëª©í‘œ ê´€ë ¨ í‚¤ ì°¾ê¸°
        goal_keywords = ['goal_name', 'task_name', 'objective', 'goal', 'task', 'ì„±ê³¼ì§€í‘œëª…', 'ê³¼ì œëª…', 'ëª©í‘œëª…']
        exclude_keywords = ['name', 'ì´ë¦„', 'ì„±ëª…']
        
        first_record = team_goals[0]
        goal_key = None
        
        # ì •í™•í•œ ë§¤ì¹­ ìš°ì„ 
        for key in goal_keywords:
            if key in first_record:
                goal_key = key
                break
        
        # í‚¤ì›Œë“œ í¬í•¨ ê²€ìƒ‰
        if not goal_key:
            for key in first_record.keys():
                key_lower = str(key).lower()
                if any(keyword in key_lower for keyword in ['goal', 'task', 'ê³¼ì œ', 'ëª©í‘œ', 'ì§€í‘œ']):
                    if not any(exclude in key_lower for exclude in exclude_keywords) or 'goal' in key_lower:
                        goal_key = key
                        break
        
        if goal_key:
            categories = list(set([
                str(record[goal_key]).strip() for record in team_goals 
                if record.get(goal_key) and str(record[goal_key]).strip() and str(record[goal_key]).strip().lower() != 'nan'
            ]))
            logger.info(f"ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ì™„ë£Œ: {categories}")
            return categories
        else:
            logger.error("ëª©í‘œ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
    
    def generate_evaluation_prompt(self, employee_data: Dict[str, Any]) -> str:
        """í‰ê°€ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        
        team_categories = self.extract_team_goal_categories(employee_data['team_goals'])
        
        if not team_categories:
            # ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©
            team_categories = ["ì¼ë°˜ì—…ë¬´", "í”„ë¡œì íŠ¸ê´€ë¦¬", "ê³ ê°ëŒ€ì‘", "ê¸°íƒ€í™œë™"]
            logger.warning(f"íŒ€ ëª©í‘œ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©: {team_categories}")
        
        prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ HR í‰ê°€ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì§ì›ì˜ ì£¼ê°„ ë³´ê³ ì„œë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ê°ê´€ì ì¸ ì„±ê³¼ í‰ê°€ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.

## í‰ê°€ ëŒ€ìƒ ì •ë³´

### ì§ì› ê¸°ë³¸ ì •ë³´
- ì´ë¦„: {employee_data['employee_info']['name']}
- ì§ì›ë²ˆí˜¸: {employee_data['employee_info']['employee_number']}
- ì†Œì†: {employee_data['employee_info']['department']} - {employee_data['employee_info']['team']}
- í‰ê°€ ê¸°ê°„: {employee_data['employee_info']['period']}
- ì´ í‰ê°€ ì£¼ì°¨: {employee_data['employee_info']['total_weeks']}ì£¼

### ì£¼ê°„ë³„ ìˆ˜í–‰ ì—…ë¬´
"""
        
        # ì£¼ê°„ë³„ ì—…ë¬´ ì¶”ê°€
        if employee_data['weekly_tasks']:
            for i, task in enumerate(employee_data['weekly_tasks'], 1):
                start_date = task.get('start_date', 'N/A')
                finish_date = task.get('finish_date', 'N/A')
                done_task = task.get('done_task', 'N/A')
                prompt += f"\n**{i}ì£¼ì°¨ ({start_date} ~ {finish_date})**\n"
                prompt += f"{done_task}\n"
        else:
            prompt += "\nì£¼ê°„ ì—…ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        
        # íŒ€ ëª©í‘œ ì¶”ê°€
        if employee_data['team_goals']:
            prompt += "\n### íŒ€ ëª©í‘œ ë° ì„±ê³¼ì§€í‘œ\n"
            for i, goal in enumerate(employee_data['team_goals'], 1):
                prompt += f"**ëª©í‘œ {i}**: {goal}\n"
        
        # íŒ€ í‰ê°€ ê¸°ì¤€ ì¶”ê°€
        if employee_data['team_criteria']:
            prompt += "\n### íŒ€ í‰ê°€ ê¸°ì¤€\n"
            for i, criteria in enumerate(employee_data['team_criteria'], 1):
                prompt += f"**ê¸°ì¤€ {i}**: {criteria}\n"
        
        # ì¹´í…Œê³ ë¦¬ ê°€ì´ë“œ
        prompt += f"""
### í™œë™ ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬
ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ì—…ë¬´ë¥¼ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:
"""
        for i, category in enumerate(team_categories, 1):
            prompt += f"{i}. {category}\n"
        
        prompt += f"""

## í‰ê°€ ê²°ê³¼ í˜•ì‹

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¢…í•© í‰ê°€ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

```json
{{
  "employee_summary": {{
    "basic_info": {{
      "name": "ì§ì›ëª…",
      "employee_number": "ì§ì›ë²ˆí˜¸",
      "period": "í‰ê°€ê¸°ê°„",
      "total_activities": "ì´ í™œë™ ìˆ˜"
    }},
    "activity_categorization": [
"""
        
        # ì¹´í…Œê³ ë¦¬ë³„ êµ¬ì¡° ë™ì  ìƒì„± (ë°°ì—´ í˜•íƒœë¡œ ë³€ê²½)
        for i, category in enumerate(team_categories):
            prompt += f"""      {{
        "category": "{category}",
        "count": 0,
        "activities": [],
        "impact": "ëª©í‘œ ë‹¬ì„±ì— ë¯¸ì¹œ ì˜í–¥ ì„¤ëª…",
        "evidence": [],
        "assessment": "í™œë™ê³¼ ëª©í‘œ ê°„ ì—°ê´€ì„± í‰ê°€"
      }}"""
            if i < len(team_categories) - 1:
                prompt += ","
            prompt += "\n"
        
        prompt += f"""    ],
    "performance_pattern_analysis": {{
      "strengths": ["ê°•ì 1", "ê°•ì 2", "ê°•ì 3"],
      "improvements": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
      "work_style": "ì—…ë¬´ ìŠ¤íƒ€ì¼ íŠ¹ì§• ìš”ì•½"
    }}
  }}
}}
```

## í‰ê°€ ê°€ì´ë“œë¼ì¸

1. **ê°ê´€ì  ë¶„ì„**: êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ ì„±ê³¼ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í‰ê°€
2. **ì¹´í…Œê³ ë¦¬ ë§¤í•‘**: ê° ì—…ë¬´ë¥¼ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜
3. **í™œë™ ë‚´ìš© ê¸°ë¡**: activities ë°°ì—´ì—ëŠ” ë°˜ë“œì‹œ ì‹¤ì œ ìˆ˜í–‰í•œ ì—…ë¬´ ë‚´ìš©ì„ ê¸°ë¡í•˜ì„¸ìš” (ì£¼ì°¨ ì •ë³´ê°€ ì•„ë‹Œ êµ¬ì²´ì ì¸ ì—…ë¬´ ì„¤ëª…)
4. **íŒ¨í„´ ì¸ì‹**: ë°˜ë³µë˜ëŠ” ì„±ê³µ ìš”ì¸ê³¼ ê°œì„  ì˜ì—­ ì‹ë³„
5. **ê· í˜•ì  í‰ê°€**: ê°•ì ê³¼ ê°œì„ ì ì„ ê· í˜•ìˆê²Œ ì œì‹œ
6. **ì‹¤í–‰ ê°€ëŠ¥ì„±**: êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©í–¥ ì œì‹œ

## ì¤‘ìš”ì‚¬í•­
- activities ë°°ì—´ì—ëŠ” "1ì£¼ì°¨", "2ì£¼ì°¨" ê°™ì€ ì£¼ì°¨ ì •ë³´ê°€ ì•„ë‹Œ, í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ì‹¤ì œë¡œ ìˆ˜í–‰í•œ êµ¬ì²´ì ì¸ ì—…ë¬´ ë‚´ìš©ì„ ê¸°ë¡í•´ì£¼ì„¸ìš”.
- ì˜ˆì‹œ: ["ê³ ê° ë¬¸ì˜ ì‘ë‹µ ë° ì´ìŠˆ í•´ê²°", "ì‹ ê·œ í”„ë¡œì íŠ¸ ê¸°íšì•ˆ ì‘ì„±", "íŒ€ ë¯¸íŒ… ì§„í–‰ ë° ì—…ë¬´ ë¶„ë°°"]

JSON í˜•ì‹ì„ ì •í™•íˆ ì¤€ìˆ˜í•˜ì—¬ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""
        
        return prompt
    
    def execute_llm_evaluation(self, prompt: str) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ í‰ê°€ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        try:
            logger.info(f"LLM í‰ê°€ ì‹¤í–‰ - ëª¨ë¸: {self.model}")
            print(f"ğŸ¤– OpenAI API í˜¸ì¶œ ì‹œì‘... (ëª¨ë¸: {self.model})")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ HR í‰ê°€ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  êµ¬ì²´ì ì¸ ì„±ê³¼ í‰ê°€ë¥¼ ì œê³µí•˜ë©°, í•­ìƒ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=4000
            )
            
            response_text = response.choices[0].message.content
            print(f"âœ… OpenAI API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (ê¸¸ì´: {len(response_text)} ë¬¸ì)")
            
            # JSON ì¶”ì¶œ ë° íŒŒì‹±
            json_text = self._extract_json_from_response(response_text)
            result = json.loads(json_text)
            
            logger.info("LLM í‰ê°€ ì™„ë£Œ")
            print("âœ… JSON íŒŒì‹± ì„±ê³µ")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "error": "JSON íŒŒì‹± ì‹¤íŒ¨",
                "raw_response": response_text if 'response_text' in locals() else "No response",
                "error_details": str(e)
            }
        except Exception as e:
            logger.error(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            print(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def _extract_json_from_response(self, response_text: str) -> str:
        """ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if "```json" in response_text:
            json_start = response_text.find("```json") + 7
            json_end = response_text.find("```", json_start)
            return response_text[json_start:json_end].strip()
        else:
            return response_text.strip()
    
    def save_evaluation_results(self, 
                               results: Dict[str, Any], 
                               filename: Optional[str] = None) -> str:
        """í‰ê°€ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"evaluation_result_{timestamp}.json"
        
        output_file = self.output_path / filename
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"í‰ê°€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        return str(output_file)
    
    def execute_single_evaluation(self, 
                                 employee_number: str,
                                 weekly_file: str = "weekly.csv",
                                 criteria_file: str = "team_criteria.csv",
                                 goals_file: str = "team_goal.csv") -> Dict[str, Any]:
        """ë‹¨ì¼ ì§ì›ì— ëŒ€í•œ ì™„ì „í•œ í‰ê°€ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        
        logger.info(f"=== ì§ì› {employee_number} í‰ê°€ ì‹œì‘ ===")
        
        try:
            # 1ë‹¨ê³„: ê³„íš ìˆ˜ë¦½
            plan = self.plan_evaluation(weekly_file, criteria_file, goals_file, [employee_number])
            
            # 2ë‹¨ê³„: ë°ì´í„° ê²€ì¦
            validation = self.validate_data_files(weekly_file, criteria_file, goals_file)
            if not validation["valid"]:
                raise ValueError(f"ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {validation['errors']}")
            
            # 3ë‹¨ê³„: ë°ì´í„° ë¡œë“œ
            self.load_and_preprocess_data(weekly_file, criteria_file, goals_file)
            
            # 4ë‹¨ê³„: ì§ì› ë°ì´í„° ë¶„ì„
            employee_data = self.analyze_employee_data(employee_number)
            
            # 5ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.generate_evaluation_prompt(employee_data)
            
            # 6ë‹¨ê³„: LLM í‰ê°€ ì‹¤í–‰
            evaluation_result = self.execute_llm_evaluation(prompt)
            
            # 7ë‹¨ê³„: ê²°ê³¼ ì €ì¥ (AI í‰ê°€ ê²°ê³¼ë§Œ)
            if "error" not in evaluation_result:
                output_file = self.save_evaluation_results(
                    evaluation_result,  # AI í‰ê°€ ê²°ê³¼ë§Œ ì €ì¥
                    f"evaluation_{employee_number}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                )
                
                # í‰ê°€ ì´ë ¥ì— ì¶”ê°€
                self.evaluation_history.append({
                    "employee_number": employee_number,
                    "timestamp": datetime.now().isoformat(),
                    "output_file": output_file,
                    "status": "success"
                })
                
                logger.info(f"ì§ì› {employee_number} í‰ê°€ ì™„ë£Œ - ì„±ê³µ")
                return evaluation_result
            else:
                # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê°„ë‹¨í•œ ê²°ê³¼ ì €ì¥
                error_result = {
                    "employee_number": employee_number,
                    "timestamp": datetime.now().isoformat(),
                    "error": evaluation_result["error"]
                }
                
                output_file = self.save_evaluation_results(
                    error_result,
                    f"evaluation_error_{employee_number}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                )
                
                self.evaluation_history.append({
                    "employee_number": employee_number,
                    "timestamp": datetime.now().isoformat(),
                    "output_file": output_file,
                    "status": "failed"
                })
                
                logger.info(f"ì§ì› {employee_number} í‰ê°€ ì‹¤íŒ¨")
                return error_result
                
        except Exception as e:
            logger.error(f"ì§ì› {employee_number} í‰ê°€ ì‹¤íŒ¨: {str(e)}")
            error_result = {
                "employee_number": employee_number,
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            }
            return error_result

    def execute_batch_evaluation(self, 
                                target_employees: Optional[List[str]] = None,
                                weekly_file: str = "weekly.csv",
                                criteria_file: str = "team_criteria.csv",
                                goals_file: str = "team_goal.csv") -> Dict[str, Any]:
        """ë‹¤ìˆ˜ ì§ì›ì— ëŒ€í•œ ë°°ì¹˜ í‰ê°€ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        
        logger.info("=== ë°°ì¹˜ í‰ê°€ ì‹œì‘ ===")
        
        try:
            # ë°ì´í„° ë¡œë“œ
            self.load_and_preprocess_data(weekly_file, criteria_file, goals_file)
            
            # ëŒ€ìƒ ì§ì› ëª©ë¡ ê²°ì •
            if target_employees is None:
                if 'employee_number' in self.weekly_data.columns:
                    target_employees = self.weekly_data['employee_number'].unique().tolist()
                else:
                    raise ValueError("employee_number ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            batch_results = {
                "batch_metadata": {
                    "start_time": datetime.now().isoformat(),
                    "target_employees": target_employees,
                    "total_employees": len(target_employees)
                },
                "individual_results": {},
                "batch_summary": {
                    "successful_evaluations": 0,
                    "failed_evaluations": 0
                }
            }
            
            # ê°œë³„ ì§ì› í‰ê°€ ì‹¤í–‰
            for employee_number in target_employees:
                logger.info(f"ë°°ì¹˜ í‰ê°€ ì§„í–‰ ì¤‘: {employee_number}")
                
                try:
                    result = self.execute_single_evaluation(
                        employee_number, weekly_file, criteria_file, goals_file
                    )
                    
                    batch_results["individual_results"][employee_number] = result
                    
                    if "error" not in result:
                        batch_results["batch_summary"]["successful_evaluations"] += 1
                    else:
                        batch_results["batch_summary"]["failed_evaluations"] += 1
                        
                except Exception as e:
                    logger.error(f"ì§ì› {employee_number} ë°°ì¹˜ í‰ê°€ ì‹¤íŒ¨: {str(e)}")
                    batch_results["individual_results"][employee_number] = {
                        "error": str(e),
                        "employee_number": employee_number
                    }
                    batch_results["batch_summary"]["failed_evaluations"] += 1
            
            batch_results["batch_metadata"]["end_time"] = datetime.now().isoformat()
            
            # ë°°ì¹˜ ê²°ê³¼ ì €ì¥
            batch_output_file = self.save_evaluation_results(
                batch_results,
                f"batch_evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )
            
            logger.info(f"ë°°ì¹˜ í‰ê°€ ì™„ë£Œ - ì„±ê³µ: {batch_results['batch_summary']['successful_evaluations']}ëª…, "
                       f"ì‹¤íŒ¨: {batch_results['batch_summary']['failed_evaluations']}ëª…")
            
            return batch_results
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ í‰ê°€ ì‹¤íŒ¨: {str(e)}")
            return {
                "batch_metadata": {
                    "start_time": datetime.now().isoformat(),
                    "error": str(e)
                },
                "batch_summary": {
                    "successful_evaluations": 0,
                    "failed_evaluations": len(target_employees) if target_employees else 0
                }
            }

    def get_evaluation_history(self) -> List[Dict[str, Any]]:
        """í‰ê°€ ì´ë ¥ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.evaluation_history

    def get_evaluation_statistics(self) -> Dict[str, Any]:
        """í‰ê°€ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.evaluation_history:
            return {"total_evaluations": 0}
        
        successful_evaluations = [
            entry for entry in self.evaluation_history 
            if entry.get("status") == "success"
        ]
        
        stats = {
            "total_evaluations": len(self.evaluation_history),
            "successful_evaluations": len(successful_evaluations),
            "failed_evaluations": len(self.evaluation_history) - len(successful_evaluations),
            "latest_evaluation": self.evaluation_history[-1]["timestamp"] if self.evaluation_history else None,
            "evaluated_employees": [entry["employee_number"] for entry in self.evaluation_history]
        }
        
        return stats


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ëª¨ë“  ì§ì› ë°°ì¹˜ í‰ê°€"""
    
    print("=== WeeklyReportEvaluationAgent ì‹œì‘ ===")
    print("ğŸ“‹ ëª¨ë“  ì§ì›ì— ëŒ€í•œ ë°°ì¹˜ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    
    # API í‚¤ ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ë¡œë“œ ì‹œë„
    api_key = None
    
     # API í‚¤ í™•ì¸ ì½”ë“œ ì¶”ê°€
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        masked_key = api_key[:10] + "*" * (len(api_key) - 15) + api_key[-5:] if len(api_key) > 15 else api_key[:5] + "*" * (len(api_key) - 5)
        print(f"ğŸ”‘ í˜„ì¬ API í‚¤: {masked_key}")
        print(f"ğŸ“ API í‚¤ ê¸¸ì´: {len(api_key)} ë¬¸ì")
        print(f"ğŸ·ï¸  API í‚¤ í˜•ì‹: {'âœ… ì˜¬ë°”ë¦„' if api_key.startswith(('sk-', 'sk-proj-')) else 'âŒ ì˜ëª»ë¨'}")
    else:
        print("âŒ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # 1. í™˜ê²½ë³€ìˆ˜ì—ì„œ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        print("âœ“ í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë°œê²¬")
    else:
        # 2. .env íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
        env_file = Path(".env")
        if env_file.exists():
            print("âœ“ .env íŒŒì¼ ë°œê²¬, ë¡œë”© ì¤‘...")
            try:
                with open(env_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith('OPENAI_API_KEY='):
                            api_key = line.split('=', 1)[1].strip()
                            os.environ['OPENAI_API_KEY'] = api_key
                            print("âœ“ .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ ì™„ë£Œ")
                            break
            except Exception as e:
                print(f"âœ— .env íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        else:
            print("âœ— .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    
    # 3. API í‚¤ê°€ ì—¬ì „íˆ ì—†ìœ¼ë©´ ì‚¬ìš©ì ì…ë ¥ ìš”ì²­
    if not api_key:
        print("\nğŸ“‹ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ì§ì ‘ ì…ë ¥")
        print("2. ì¢…ë£Œ í›„ í™˜ê²½ë³€ìˆ˜ ì„¤ì •")
        
        choice = input("\nì„ íƒ (1 ë˜ëŠ” 2): ").strip()
        if choice == '1':
            api_key = input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            if not api_key:
                print("âŒ API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return
        else:
            print("âŒ í™˜ê²½ë³€ìˆ˜ ì„¤ì • í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            print("Windows: set OPENAI_API_KEY=your-key")
            print("Linux/Mac: export OPENAI_API_KEY=your-key")
            return
    
    try:
        print(f"\nğŸ¤– ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘... (ëª¨ë¸: gpt-4-turbo)")
        
        # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        agent = WeeklyReportEvaluationAgent(
            api_key=api_key,
            model="gpt-4-turbo",
            base_data_path="../data",  # ìƒìœ„ í´ë”ì˜ data ë””ë ‰í† ë¦¬
            output_path="./output"
        )
        
        print("âœ… ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ!")
        
        # ë°ì´í„° ë¡œë“œí•´ì„œ ì§ì› ìˆ˜ ë¯¸ë¦¬ í™•ì¸
        print("\nğŸ“Š ë°ì´í„° ë¶„ì„ ì¤‘...")
        agent.load_and_preprocess_data(
            weekly_file="weekly.csv",
            criteria_file="team_criteria.csv", 
            goals_file="team_goal.csv"
        )
        
        # í‰ê°€ ëŒ€ìƒ ì§ì› ëª©ë¡ í™•ì¸
        if 'employee_number' in agent.weekly_data.columns:
            target_employees = agent.weekly_data['employee_number'].unique().tolist()
            print(f"ğŸ“‹ í‰ê°€ ëŒ€ìƒ ì§ì›: {len(target_employees)}ëª…")
            print(f"   ì§ì› ëª©ë¡: {target_employees}")
            
            # ì‚¬ìš©ì í™•ì¸
            proceed = input(f"\n{len(target_employees)}ëª…ì˜ ì§ì›ì„ í‰ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
            if proceed not in ['y', 'yes']:
                print("âŒ í‰ê°€ë¥¼ ì·¨ì†Œí•©ë‹ˆë‹¤.")
                return
        else:
            print("âŒ employee_number ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°°ì¹˜ í‰ê°€ ì‹¤í–‰
        print(f"\nğŸš€ {len(target_employees)}ëª… ë°°ì¹˜ í‰ê°€ ì‹œì‘...")
        print("â° ì´ ì‘ì—…ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...")
        
        batch_result = agent.execute_batch_evaluation(
            target_employees=None,  # Noneì´ë©´ ëª¨ë“  ì§ì› ìë™ ì„ íƒ
            weekly_file="weekly.csv",
            criteria_file="team_criteria.csv", 
            goals_file="team_goal.csv"
        )
        
        # ë°°ì¹˜ í‰ê°€ ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ¯ === ë°°ì¹˜ í‰ê°€ ì™„ë£Œ ===")
        print(f"ğŸ“Š ì´ ëŒ€ìƒ ì§ì›: {batch_result['batch_metadata']['total_employees']}ëª…")
        print(f"âœ… ì„±ê³µí•œ í‰ê°€: {batch_result['batch_summary']['successful_evaluations']}ê±´")
        print(f"âŒ ì‹¤íŒ¨í•œ í‰ê°€: {batch_result['batch_summary']['failed_evaluations']}ê±´")
        
        # ê°œë³„ ê²°ê³¼ ê°„ë‹¨ ìš”ì•½
        print(f"\nğŸ“‹ ê°œë³„ í‰ê°€ ê²°ê³¼:")
        for emp_num, result in batch_result['individual_results'].items():
            if "error" in result:
                print(f"   {emp_num}: âŒ ì‹¤íŒ¨ - {result['error'][:50]}...")
            else:
                emp_name = result.get('employee_summary', {}).get('basic_info', {}).get('name', 'Unknown')
                print(f"   {emp_num} ({emp_name}): âœ… ì„±ê³µ")
        
        # ìµœì¢… í†µê³„
        stats = agent.get_evaluation_statistics()
        print(f"\nğŸ“ˆ === ìµœì¢… í†µê³„ ===")
        print(f"ì´ í‰ê°€ ìˆ˜í–‰: {stats['total_evaluations']}ê±´")
        print(f"ì„±ê³µë¥ : {(stats['successful_evaluations']/stats['total_evaluations']*100):.1f}%" if stats['total_evaluations'] > 0 else "N/A")
        
        # ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜ ì•ˆë‚´
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜:")
        print(f"   - ê°œë³„ í‰ê°€ íŒŒì¼: ./output/evaluation_[ì§ì›ë²ˆí˜¸]_[íƒ€ì„ìŠ¤íƒ¬í”„].json")
        print(f"   - ë°°ì¹˜ ê²°ê³¼ íŒŒì¼: ./output/batch_evaluation_[íƒ€ì„ìŠ¤íƒ¬í”„].json")
        
    except Exception as e:
        logger.error(f"ë©”ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise


if __name__ == "__main__":
    main()