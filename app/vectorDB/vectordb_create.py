import pymysql
from openai import OpenAI
import pinecone
import numpy as np
import json
from typing import List, Dict, Any
import time
from tqdm import tqdm

class RDBToPineconeBuilder:
    def __init__(self, 
                 pinecone_api_key: str,
                 openai_api_key: str,
                 db_config: Dict[str, Any]):
        """
        RDB ë°ì´í„°ë¥¼ Pinecone ë²¡í„° DBë¡œ êµ¬ì¶•í•˜ëŠ” í´ë˜ìŠ¤
        
        Args:
            pinecone_api_key: Pinecone API í‚¤
            openai_api_key: OpenAI API í‚¤
            db_config: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
        """
        self.pinecone_api_key = pinecone_api_key
        self.openai_api_key = openai_api_key
        self.db_config = db_config
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.openai_client = OpenAI(api_key=self.openai_api_key)
        
        # Pinecone ì´ˆê¸°í™” ì‹œë„ (ì—¬ëŸ¬ í™˜ê²½ í…ŒìŠ¤íŠ¸)
        self.pinecone_initialized = False
        environments_to_try = [
            None,  # ìµœì‹  ë²„ì „ì—ì„œëŠ” environment ë¶ˆí•„ìš”í•  ìˆ˜ ìˆìŒ
            "us-east1-gcp",
            "us-west1-gcp",
            "asia-northeast1-gcp",
            "europe-west1-gcp"
        ]
        
        for env in environments_to_try:
            try:
                if env is None:
                    # ìµœì‹  ë²„ì „ ë°©ì‹ ì‹œë„
                    pinecone.init(api_key=self.pinecone_api_key)
                else:
                    # êµ¬ë²„ì „ ë°©ì‹ ì‹œë„
                    pinecone.init(api_key=self.pinecone_api_key, environment=env)
                
                self.pinecone_initialized = True
                print(f"âœ… Pinecone ì´ˆê¸°í™” ì„±ê³µ" + (f" (í™˜ê²½: {env})" if env else ""))
                break
            except Exception as e:
                continue
        
        if not self.pinecone_initialized:
            raise Exception("âŒ Pinecone ì´ˆê¸°í™” ì‹¤íŒ¨. API í‚¤ ë˜ëŠ” í™˜ê²½ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        # ì„¤ì •ê°’ (ë¬´ë£Œ í”Œëœ ê³ ë ¤)
        self.embedding_model = "text-embedding-3-small"
        self.dimension = 1536  # text-embedding-3-small ê¸°ë³¸ ì°¨ì› (1024ê°€ ì•„ë‹Œ 1536)
        self.index_name = "skore"
        self.namespace = "personal_weekly"
        
    def connect_to_db(self):
        """MariaDB ì—°ê²°"""
        try:
            connection = pymysql.connect(
                host=self.db_config['host'],
                port=self.db_config['port'],
                user=self.db_config['username'],
                password=self.db_config['password'],
                database=self.db_config['database'],
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor
            )
            print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
            return connection
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def fetch_weekly_reports(self, connection) -> List[Dict]:
        """weekly_reports í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        try:
            with connection.cursor() as cursor:
                # í…Œì´ë¸” êµ¬ì¡° í™•ì¸
                cursor.execute("DESCRIBE weekly_reports")
                columns = cursor.fetchall()
                print("ğŸ“‹ í…Œì´ë¸” êµ¬ì¡°:")
                for col in columns:
                    print(f"  - {col['Field']}: {col['Type']}")
                
                # ì „ì²´ ë°ì´í„° ì¡°íšŒ
                cursor.execute("SELECT * FROM weekly_reports")
                results = cursor.fetchall()
                print(f"ğŸ“Š ì´ {len(results)}ê°œì˜ ë ˆì½”ë“œë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
                return results
                
        except Exception as e:
            print(f"âŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def create_embedding_text(self, record: Dict) -> str:
        """
        ë ˆì½”ë“œë¥¼ ì„ë² ë”©í•  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        weekly_reports í…Œì´ë¸”ì˜ í•„ë“œì— ë§ê²Œ ìµœì í™”
        """
        text_parts = []
        
        # done_taskê°€ ë©”ì¸ ë‚´ìš©ì´ë¯€ë¡œ ìš°ì„ ì ìœ¼ë¡œ í¬í•¨
        if record.get('done_task'):
            text_parts.append(f"ì™„ë£Œ ì—…ë¬´: {record['done_task']}")
        
        # ì‚¬ìš©ì IDì™€ ì¡°ì§ ID ì¶”ê°€
        if record.get('user_id'):
            text_parts.append(f"ì‚¬ìš©ì ID: {record['user_id']}")
        
        if record.get('organization_id'):
            text_parts.append(f"ì¡°ì§ ID: {record['organization_id']}")
        
        # ê¸°ê°„ ì •ë³´ ì¶”ê°€
        if record.get('start_date') and record.get('end_date'):
            text_parts.append(f"ê¸°ê°„: {record['start_date']} ~ {record['end_date']}")
        
        # í‰ê°€ ì •ë³´ ì¶”ê°€
        if record.get('evaluation_year') and record.get('evaluation_quarter'):
            text_parts.append(f"í‰ê°€: {record['evaluation_year']}ë…„ {record['evaluation_quarter']}ë¶„ê¸°")
        
        return " | ".join(text_parts)
    
    def get_embedding(self, text: str) -> List[float]:
        """OpenAI APIë¥¼ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        try:
            response = self.openai_client.embeddings.create(
                model=self.embedding_model,
                input=text
                # dimensions íŒŒë¼ë¯¸í„° ì œê±° (ê¸°ë³¸ 1536 ì°¨ì› ì‚¬ìš©)
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def setup_pinecone_index(self):
        """Pinecone ì¸ë±ìŠ¤ ì„¤ì •"""
        try:
            # ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸
            existing_indexes = pinecone.list_indexes()
            
            if self.index_name not in existing_indexes:
                # ì¸ë±ìŠ¤ ìƒì„± (êµ¬ë²„ì „ ë°©ì‹)
                pinecone.create_index(
                    name=self.index_name,
                    dimension=self.dimension,
                    metric='cosine'
                )
                print(f"âœ… ì¸ë±ìŠ¤ '{self.index_name}' ìƒì„± ì™„ë£Œ")
                
                # ì¸ë±ìŠ¤ ì´ˆê¸°í™” ëŒ€ê¸°
                time.sleep(60)
            else:
                print(f"âœ… ì¸ë±ìŠ¤ '{self.index_name}' ì´ë¯¸ ì¡´ì¬í•¨")
            
            # ì¸ë±ìŠ¤ ì—°ê²°
            self.index = pinecone.Index(self.index_name)
            return True
            
        except Exception as e:
            print(f"âŒ Pinecone ì¸ë±ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    
    def upsert_to_pinecone(self, records: List[Dict]):
        """Pineconeì— ë²¡í„° ë°ì´í„° ì—…ì„œíŠ¸"""
        vectors = []
        
        print("ğŸ”„ ì„ë² ë”© ìƒì„± ë° Pinecone ì—…ë¡œë“œ ì¤‘...")
        
        for i, record in enumerate(tqdm(records, desc="ì²˜ë¦¬ ì¤‘")):
            # ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ìƒì„±
            text = self.create_embedding_text(record)
            if not text.strip():
                continue
            
            # ì„ë² ë”© ìƒì„±
            embedding = self.get_embedding(text)
            if embedding is None:
                continue
            
            # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
            metadata = {
                'text': text,
                'source_table': 'weekly_reports',
                'namespace': self.namespace,
                'user_id': str(record.get('user_id', '')),
                'organization_id': str(record.get('organization_id', '')),
                'start_date': str(record.get('start_date', '')),
                'end_date': str(record.get('end_date', '')),
                'evaluation_year': str(record.get('evaluation_year', '')),
                'evaluation_quarter': str(record.get('evaluation_quarter', ''))
            }
            
            # ë²¡í„° ë°ì´í„° ì¤€ë¹„
            vector_data = {
                'id': f"weekly_report_{record.get('id', i)}",
                'values': embedding,
                'metadata': metadata
            }
            
            vectors.append(vector_data)
            
            # ë°°ì¹˜ ì²˜ë¦¬ (100ê°œì”©)
            if len(vectors) >= 100:
                try:
                    self.index.upsert(
                        vectors=vectors,
                        namespace=self.namespace
                    )
                    vectors = []
                    time.sleep(1)  # API ì œí•œ ë°©ì§€
                except Exception as e:
                    print(f"âŒ ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ë‚¨ì€ ë²¡í„°ë“¤ ì—…ë¡œë“œ
        if vectors:
            try:
                self.index.upsert(
                    vectors=vectors,
                    namespace=self.namespace
                )
                print("âœ… ëª¨ë“  ë²¡í„° ì—…ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ìµœì¢… ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def get_index_stats(self):
        """ì¸ë±ìŠ¤ í†µê³„ í™•ì¸"""
        try:
            stats = self.index.describe_index_stats()
            print("ğŸ“Š Pinecone ì¸ë±ìŠ¤ í†µê³„:")
            print(f"  - ì „ì²´ ë²¡í„° ìˆ˜: {stats.total_vector_count}")
            print(f"  - ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ í†µê³„: {stats.namespaces}")
            return stats
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def run_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ RDB to Pinecone ë²¡í„° DB êµ¬ì¶• ì‹œì‘")
        
        # 1. DB ì—°ê²°
        connection = self.connect_to_db()
        if not connection:
            return False
        
        try:
            # 2. ë°ì´í„° ì¡°íšŒ
            records = self.fetch_weekly_reports(connection)
            if not records:
                print("âŒ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # 3. Pinecone ì¸ë±ìŠ¤ ì„¤ì •
            if not self.setup_pinecone_index():
                return False
            
            # 4. ì„ë² ë”© ë° ì—…ë¡œë“œ
            self.upsert_to_pinecone(records)
            
            # 5. ê²°ê³¼ í™•ì¸
            self.get_index_stats()
            
            print("âœ… ë²¡í„° DB êµ¬ì¶• ì™„ë£Œ!")
            return True
            
        finally:
            connection.close()
            print("ğŸ”Œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ")

# ê²€ìƒ‰ ì˜ˆì‹œ í•¨ìˆ˜
def search_vectors(query: str, pinecone_api_key: str, openai_api_key: str, top_k: int = 5):
    """ë²¡í„° ê²€ìƒ‰ ì˜ˆì‹œ"""
    # OpenAIë¡œ ì¿¼ë¦¬ ì„ë² ë”©
    client = OpenAI(api_key=openai_api_key)
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=query,
        dimensions=1024
    )
    query_embedding = response.data[0].embedding
    
    # Pinecone ê²€ìƒ‰ (êµ¬ë²„ì „ ë°©ì‹)
    pinecone.init(api_key=pinecone_api_key)
    index = pinecone.Index("skore")
    
    results = index.query(
        vector=query_embedding,
        top_k=top_k,
        namespace="personal_weekly",
        include_metadata=True
    )
    
    print(f"ğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼:")
    for i, match in enumerate(results.matches, 1):
        print(f"\n{i}. ì ìˆ˜: {match.score:.4f}")
        print(f"   ID: {match.id}")
        print(f"   í…ìŠ¤íŠ¸: {match.metadata.get('text', 'N/A')[:200]}...")

def init_resources(pinecone_api_key: str, openai_api_key: str, index_name: str):
    """í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”"""
    # OpenAI ì„¤ì •
    openai_client = OpenAI(api_key=openai_api_key)
    
    # Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (êµ¬ë²„ì „)
    pinecone.init(api_key=pinecone_api_key)
    pinecone_index = pinecone.Index(index_name)
    
    print(f"âœ… ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ. ì¸ë±ìŠ¤: {index_name}")
    
    return openai_client, pinecone_index

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì„¤ì •ê°’ (ë³´ì•ˆìƒ ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥)
    PINECONE_API_KEY = "pcsk_79HynK_8MFWKGTDNiaopX94jbQxLi5E1dpB546X6idHGtMHQifHYyguSJG5AxNECTQeLFW"
    OPENAI_API_KEY = "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"
    
    DB_CONFIG = {
        'host': '13.209.110.151',
        'port': 3306,
        'username': 'root',
        'password': 'root',
        'database': 'skala'
    }
    
    # ë²¡í„° DB êµ¬ì¶• ì‹¤í–‰
    builder = RDBToPineconeBuilder(
        pinecone_api_key=PINECONE_API_KEY,
        openai_api_key=OPENAI_API_KEY,
        db_config=DB_CONFIG
    )
    
    builder.run_pipeline()